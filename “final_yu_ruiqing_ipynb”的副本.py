# -*- coding: utf-8 -*-
"""“Final_Yu_Ruiqing.ipynb”的副本

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uLVFrCj8sLmPt_2v4GsNnIbiZ3hXEEpq

## **Machine Learning Final Project DUE: Friday May 7th 11:59pm**

**Note: Please read all the instructions carefully before starting the project.**

For your final project you will build an ML model to analyze a dataset of your choice. You are welcome to keep working on the data in your EDA project if your data is large enough (at least 1000 rows for simple models and at least 10,000 for more complex models) or you can choose from the datasets/project suggestions below.

In this project make sure that you:
- Have a large enough dataset
- Split your data in training and testing
- Explore your data to inform which type of model to choose (no need if you are using your EDA dataset)
- Try different models on your training dataset - then select the most promising model
- Use cross validation to fine tune the model’s parameters such as alpha in lasso
- Simplify your model using regularization, prunnning, drop-out, etc. to avoid overfitting
- Communicate your model’s performance and make sure you compare it to a benchmark when appropriate
- Plot interesting graphs and results
- Write and publish your article to medium
- Commit your code to your GitHub

Please ensure you handle all the preprocessing before the modeling.

Suggestions for project:
You can take a look at the resources given below for choosing a dataset for your project. 

- Traffic sign detection - https://benchmark.ini.rub.de/gtsdb_dataset.html
- Cat and dog classifier - https://www.kaggle.com/c/dogs-vs-cats/data
- Other datasets from Kaggle - https://www.kaggle.com/data/41592

## **Grading Criteria**

- Show clear exploration of the data to justify model choice
- Train mutliple models and clearly articulate why you chose your final model
- Show your performance on test dataset
- Clear and concise write-up with clear well-documented figures
- Commit your code to GitHub

## **Submission Details**

This is an individual assignment. You may not work in groups. The assignment is due on Friday (05/07/2021)
- To submit your assignment, download your notebook and the dataset, zip the dataset and notebook, and submit the zipped file on blackboard.
- Make sure the notebook is named in the format - Final_LastName_FirstName. If you are submitting a zipped file, please name the file as well in the same format.
- Please include the link to access your blog and your github repo in your notebook.
- Also include the link to your notebook, github repo and the blog in the submission on blackboard. Please ensure the TAs have the required access to your notebooks and the github repo.

**Note - If the dataset is too large to be zipped and submitted on blackboard, only submit your notebook, add your dataset to your google drive and share a link to the file in your notebook.**
"""

# Medium link
# https://ruiqingy-95685.medium.com/regressions-on-followers-of-top-streamers-on-twitch-2f4f9a068b13

# Start solution here
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from numpy import mean
from numpy import std
from numpy import absolute
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from yellowbrick.regressor import ResidualsPlot
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import Ridge

data = pd.read_csv("twitchdata-update.csv")
data.head()

# partition data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)

# linear Regression
data_clean = data.drop(["Channel","Partnered", "Mature", "Language"], axis=1)
model = LinearRegression()
x= data_clean["Followers gained"]
y = data_clean.iloc[:, 4]
X = x[:, np.newaxis]
model.fit(X, y)


y_predicted = model.predict(X)
plt.scatter(x, y)
plt.plot(x, y_predicted)
plt.xlabel("Followers gained")
plt.ylabel("Followers")
plt.title("Followers gained vs. Followers")
plt.show()


visualizer = ResidualsPlot(model)
visualizer.fit(X, y)
plt.show()

# Ridge Regression
from sklearn.model_selection import GridSearchCV

data1 = data_clean.iloc[:, 0:4]
data2 = data_clean.iloc[:, 5:]
y = data_clean.iloc[:, 4]
X = pd.concat([data1, data2], axis=1, join="inner")
print(X.shape) 
print(y.shape)

clf = Ridge()
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
grid = dict()
grid['alpha'] = np.arange(0, 1, 0.01)
search = GridSearchCV(clf, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)
results = search.fit(X, y)
print('MAE: %.3f' % results.best_score_)
print('Config: %s' % results.best_params_)

model = Ridge(alpha=0.99)
model.fit(X, y)
model.score(X, y)

# Lasso Regression
from sklearn.linear_model import Lasso
data1 = data_clean.iloc[:, 0:4]
data2 = data_clean.iloc[:, 5:]
y = data_clean.iloc[:, 4]
X = pd.concat([data1, data2], axis=1, join="inner")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)

cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
grid = dict()
grid['alpha'] = np.arange(0, 1, 0.01)
search = GridSearchCV(clf, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)
results = search.fit(X, y)
print('MAE: %.3f' % results.best_score_)
print('Config: %s' % results.best_params_)

lasso = Lasso(alpha=1)
lasso.fit(X_train,y_train)
train_score=lasso.score(X_train,y_train)
test_score=lasso.score(X_test,y_test)
print("training score:", train_score) 
print("test score: ", test_score)
lasso.fit(X,y)
print(lasso.score(X,y))

